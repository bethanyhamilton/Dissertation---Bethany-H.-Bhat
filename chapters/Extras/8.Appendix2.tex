

\chapter{Derivations Related to the Test of One Categorical Study-level Predictor} \label{App: onecat}
 






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
For one categorical moderator, let $C$ be the number of categories in the predictor. For this moderator, let $J_1..J_C$ be the number of studies in each category. To obtain the correct form of the design matrix, $\mathbf{X}$, I am using the no-intercept formulation. In the context of a no-intercept model, each $\hat{\beta_c}$ represents the overall pooled effect size for category $c$. Let $\hat{\beta}_c$ represent the estimated regression coefficient $\beta$ corresponding to category $c$, where the moderator is dummy coded to indicate membership. Since we are setting up a no-intercept model, $\hat{\beta}_c$ is the overall pooled effect for a given $c$ category. 


 As in Equation \ref{eq: no-intercept independent} and Equation \ref{eq: no-intercept dependent}, I will use dummy variables defined as $b_{ijc}$ for effect size $i$, study $j$, and category $c$. At the study level, it will be $b_{jc}$ and define $\mathbf{b}_{j}$ as the $C \times 1$ vector of study-level dummy variables. By parameterizing it this was, I substitute $ b_{jc}$ for the covariates, $x_{ijc}$, of a standard meta-regression model formation. 
 
 Let $\mathbf{X}_{jc} = \mathbf{1}_{jc}\mathbf{b}_{jc}$ where $\mathbf{1}_{jc}$ is a $k_{jc} \times 1$ vector of 1â€™s. For a meta-regression model that only includes categories that vary between studies, the weighted least squares estimator based on dependent effect size estimates (equation) is equivalent to a weighted least squares regression of the study-level average effect sizes, $\overline{T}_{jc}$ which is: 
\begin{equation}
     \overline{T}_{jc} = \frac{1}{k_{jc}}\sum_{i=1}^{k_{jc}}T_{ijc}
\end{equation}
 
Let $\mathbf{W}_{1}, ..., \mathbf{W}_{J} $ denote a set of symmetric weight matrices, where $\mathbf{W}_{c}$ is of the dimensions $k_{j} \times k_{j}$ and might or might not have diagonal entries. The study-level weights from Equation \ref{eq: CHEweights-study} is equal to: $\tilde{w}_{j} = \mathbf{1}'_{j}\mathbf{W}_{j}\mathbf{1}_{j}$. 

If $\hat{\bm{\beta}}$ is the full vector of coefficients than the $c$th element is $\hat{\beta}_c  = \bm{e}_c' \hat{\bm{\beta}}$ where $\bm{e}_c' $ is a vector of $C \times 1$ with a 1 in position $c$, and 0 elsewhere Using the new parametrization for the study-level weight, the weighted least squares estimate for $\hat{\beta}_c$ is:
\begin{equation} \label{eq: weighted least squares estimate for beta_c}
    \hat{\beta}_c = \bm{e}_c'\left(\sum_{j=1}^{J} \tilde{w}_{j} \mathbf{b}_{j}'\mathbf{b}_{j}  \right)^{-1} \left(\sum_{j=1}^{J} \tilde{w}_{j} \mathbf{b}_{j}'\overline{T}_{j} \right).
\end{equation}
where $\mathbf{b}_{j}$ is the dummy coding for the category of study $j$ and it sums over all categories. 


if only summing over studies in category $c$, $\mathbf{b}_{jc}$ is a vector with 1 in position $c$ and $\mathbf{b}_{jc}'\mathbf{b}_{jc}=1$, and $\mathbf{b}_{jc}'\overline{\mathbf{T}}_{jc}=\overline{\mathbf{T}}_{jc}$, which simplifies to:

\begin{equation}
    \hat{\beta}_c = \frac{\sum_{j=1}^{Jc}\tilde{w}_{jc} \overline{T}_{jc}}{\sum_{j=1}^{Jc}\tilde{w}_{jc}}
\end{equation}





If the CHE model is the correct model for the data structure, then $Var(\hat{\beta}_c) \approx \frac{1}{W_c}$ where $W_c$ is calculated using estimated variance components rather than parameter values, so it is approximated. 

In this context, $\hat{\beta}_c$ is equivalent to the average effect for category $c$ across studies when a no-intercept model is specified. 
%This is because $\mathbf{e}_c'$ is a row vector of $1 \times C$ dimensions. 
Simplifying the first term in weighted least squares estimate for $\hat{\beta}_c$, $\left(\sum_{j=1}^{J}\mathbf{b}_{j}'\tilde{w}_{j} \mathbf{b}_{j} \right)^{-1}$, we obtain the inverse of the sum of the weights only included in category ($c$) after using the dummy variables:
because each $\mathbf{b}_j = \bm(e)_c$ when study $j$ is in category $c$, the summation because only the subset of $J_c$ (studies in category $c$)
\begin{equation}
    \left(\sum_{j=1}^{Jc}\tilde{w}_{j}\mathbf{e}_{c}' \mathbf{e}_{c} \right)^{-1} = \left(\sum_{j=1}^{Jc}\tilde{w}_{jc}  \right)^{-1} = \frac{1}{W_c}
    \nonumber
\end{equation}
where  $W_c$ is the sum of the study-level weights for each category $c$.

Furthermore, simplifying for the second term in the weighted least squares estimate for $\hat{\beta}_c$, $\left(\sum_{j=1}^{Jc}\mathbf{b}_{jc}'\tilde{w}_{jc}\overline{T}_{jc} \right)$:
\begin{equation}
    \left(\sum_{j=1}^{Jc}\mathbf{b}_{jc}'\tilde{w}_{jc}\overline{T}_{jc} \right) = \left(\sum_{j=1}^{Jc} \ddot{w}_{jc} \ddot{\overline{T}}_{jc}\right) 
    \nonumber
\end{equation}
results in the sum of the weights only included in category $c$ ($\ddot{w}_{jc}$) times the average effect sizes for category $c$.

In conclusion, Equation \ref{eq: weighted least squares estimate for beta_c} will reduce to:
\begin{equation}
    \hat{\beta}_c = \frac{1}{W_c} \times \left(\sum_{j=1}^{Jc} \ddot{w}_{jc} \ddot{\overline{T}}_{jc}\right) = \mu_c
\end{equation}
where $\mu_c$ is the overall weighted average for category $c$.

Additionally, $var(\hat{\beta})$ for the CHE model becomes:

\begin{equation}
    \begin{split}
        var(\hat{\beta_c}) & = \left(\sum_{j=1}^{Jc}\mathbf{b}_{jc}'\tilde{w}_{jc} \mathbf{b}_{jc} \right)^{-1} \left(\sum_{j=1}^{Jc} \mathbf{b}_{jc}' \mathbf{1}_{jc}'\mathbf{W}_{jc} \mathbf{\Phi}_{jc} \mathbf{W}_{jc}\mathbf{1}_{jc}\mathbf{b}_{jc}   \right)\left(\sum_{j=1}^{Jc}\mathbf{b}_{jc}'\tilde{w}_{jc} \mathbf{b}_{jc} \right)^{-1} \\ 
        & = \frac{1}{W_c} \left(\sum_{j=1}^{Jc} \mathbf{b}_{jc}' \mathbf{1}_{jc}'\mathbf{W}_{jc} \mathbf{\Phi}_{jc} \mathbf{W}_{jc}\mathbf{1}_{jc}\mathbf{b}_{jc}   \right)\frac{1}{W_c} \\
        & = \frac{1}{W_c} \left(\sum_{j=1}^{Jc} \mathbf{b}_{jc}' \mathbf{1}_{jc}'\mathbf{\Phi}_{jc}^{-1} \mathbf{\Phi}_{jc} \mathbf{W}_{jc}\mathbf{1}_{jc}\mathbf{b}_{jc}   \right)\frac{1}{W_c} \\ 
        & = \frac{1}{W_c} \left(\sum_{j=1}^{Jc} \mathbf{b}_{jc}' \mathbf{1}_{jc}' \mathbf{W}_{jc}\mathbf{1}_{jc}\mathbf{b}_{jc}   \right)\frac{1}{W_c} \\ 
        & = \frac{1}{W_c} \left(\sum_{j=1}^{Jc} \mathbf{b}_{jc}' \tilde{w}_{jc}\mathbf{b}_{jc}   \right)\frac{1}{W_c} \\ 
        & = \frac{1}{W_c} W_c\frac{1}{W_c} \\ 
        & = \frac{1}{W_c} 
    \end{split}
\end{equation}



Now for the moments of $\mathbf{V}^R$, the RVE estimator of $Var(\beta)$, we need the following expression: $\mathbf{\Omega} = \mathbf{C}Var(\beta)\mathbf{C}'$. 
%$\mathbf{C}$ is a contrast matrix with $(C-1) \times C$ dimensions. 
For our purposes, we want to test the null that all categories are equal, so the contrast matrix, $\mathbf{C}$, will have $-1$'s in the first column representing that we are comparing all other categories to the first category. Then, the rest of the columns will be dummy coded with a 1 to represent that category and 0 for all other categories. So, for $\mathbf{\omega}$, it will result in the variance of the first category on the off diagonals and the sum of the first category variance with a comparison category variance on the off diagonals. 

%$\mathbf{\Omega} = \mathbf{C}Var(\bm{\hat{\beta}})\mathbf{C}'$ is the true variance of $(\mathbf{C}\\bm{\hat{\beta}}-\mathbf{c})$. It requires the true structure of the variance covariance matrix. 

%Then, for the hypothesis testing-- for a set of $\beta_c$ we would use Wald's test with constraints. ( Constrain to be equal) to compare the intercept for each level of the predictor. We will next derive the power approximations for this test.    The C matrix will have $-1$ for the first column for the first category $p=1$ then the other columns $p = 2, \dots, p$ they will be dummy coded. the dimensions will be $p-1 \times p$ for the C matrix. 


Now $\mathbf{D}$ is a $(C-1) \times (C-1)$ matrix that is equal to $\mathbf{D}= \mathbf{\Omega}^{-1/2}\mathbf{C}\mathbf{V}^R\mathbf{C}'\mathbf{\Omega}^{-1/2}$. 

Now rewriting $\mathbf{V}^R$ for the study-level categorical context: 

\begin{equation}
    \mathbf{V}^R_c = \left(\sum_{j=1}^{Jc}\mathbf{b}_{jc}'\tilde{w}_{jc} \mathbf{b}_{jc} \right)^{-1} \left(\sum_{j=1}^{Jc} \mathbf{b}_{jc}' \mathbf{1}_{jc}'\mathbf{W}_{jc} \mathbf{A}_{jc} \mathbf{e}_{jc} \mathbf{e}_{jc}' \mathbf{A}_{jc}'  \mathbf{W}_{jc}\mathbf{1}_{jc}\mathbf{b}_{jc}   \right) \left(\sum_{j=1}^{Jc}\mathbf{b}_{jc}'\tilde{w}_{jc} \mathbf{b}_{jc} \right)^{-1}
\end{equation}

should reduce to 

\begin{equation}
\begin{split}
    \mathbf{V}^R_c &= \frac{1}{W_c} \left(\sum_{j=1}^{Jc} \mathbf{b}_{jc}' \mathbf{1}_{jc}'\mathbf{W}_{jc} \mathbf{A}_{jc} \mathbf{e}_{jc} \mathbf{e}_{jc}' \mathbf{A}_{jc}'  \mathbf{W}_{jc}\mathbf{1}_{jc}\mathbf{b}_{jc}   \right) \frac{1}{W_c} \\
    &= \frac{1}{W_c} \left(\sum_{j=1}^{Jc} \mathbf{b}_{jc}' \mathbf{1}_{jc}'\mathbf{W}_{jc} \mathbf{A}_{jc} \left(\overline{T}_{jc} \mathbf{1}_{jc} - \mathbf{1}_{jc}\mathbf{b}_{jc}\mathbf{\beta}_{c} \right) \left(\overline{T}_{jc} \mathbf{1}_{jc} - \mathbf{1}_{jc}\mathbf{b}_{jc}\mathbf{\beta}_{c} \right)' \mathbf{A}_{jc}'  \mathbf{W}_{jc}\mathbf{1}_{jc}\mathbf{b}_{jc}   \right) \frac{1}{W_c} \\
    &= \frac{1}{W_c} \left(\sum_{j=1}^{Jc} \mathbf{b}_{jc}' \mathbf{1}_{jc}'\mathbf{W}_{jc} \mathbf{A}_{jc} \left[\mathbf{1}_{jc}\left(\overline{T}_{jc} \mathbf{I}_{jc}  - \mathbf{\beta}_{c} \right) \right] \left[\mathbf{1}_{jc}\left(\overline{T}_{jc} \mathbf{I}_{jc} - \mathbf{\beta}_{c} \right) \right]' \mathbf{A}_{jc}'  \mathbf{W}_{jc}\mathbf{1}_{jc}\mathbf{b}_{jc}   \right) \frac{1}{W_c} \\
    &= \frac{1}{W_c} \left(\sum_{j=1}^{Jc} \mathbf{b}_{jc}' \mathbf{1}_{jc}'\mathbf{W}_{jc} \mathbf{A}_{jc} \left[\mathbf{1}_{jc}\left(\overline{T}_{jc}   - \mathbf{\mu}_{c} \right) \right] \left[\mathbf{1}_{jc}\left(\overline{T}_{jc}  - \mathbf{\mu}_{c} \right) \right]' \mathbf{A}_{jc}'  \mathbf{W}_{jc}\mathbf{1}_{jc}\mathbf{b}_{jc}   \right) \frac{1}{W_c} \\
    &= \frac{1}{W_c} \left(\sum_{j=1}^{Jc} \frac{ \mathbf{b}_{jc}' \mathbf{1}_{jc}'\mathbf{W}_{jc}}{\sqrt{1-\frac{\ddot{w}}{W_c}}}   \mathbf{1}_{jc} \mathbf{1}_{jc}' \left(\overline{T}_{jc} - \mu_c \right)^2 \frac{  \mathbf{W}_{jc} \mathbf{1}_{jc} \mathbf{b}_{jc}}{\sqrt{1-\frac{\ddot{w}}{W_c}}}  \right) \frac{1}{W_c} \\
    &= \frac{1}{W_c} \left(\sum_{j=1}^{Jc}  \mathbf{b}_{jc}' \mathbf{1}_{jc}'\mathbf{W}_{jc} \mathbf{1}_{jc} \mathbf{1}_{jc}' \mathbf{W}_{jc} \mathbf{1}_{jc} \mathbf{b}_{jc}   \frac{\left(\overline{T}_{jc} - \mu_c \right)^2}{1-\frac{\ddot{w}}{W_c}}   \right) \frac{1}{W_c} \\
    &= \frac{1}{W_c} \left(\sum_{j=1}^{Jc}  \mathbf{b}_{jc}' \tilde{w}_{jc} \tilde{w}_{jc} \mathbf{b}_{jc}   \frac{\left(\overline{T}_{jc} - \mu_c \right)^2}{1-\frac{\ddot{w}}{W_c}}   \right) \frac{1}{W_c} \\
    &= \frac{1}{W_c^2} \left(\sum_{j=1}^{Jc}   \frac{\tilde{w}_{jc}^2\left(\overline{T}_{jc} - \mu_c \right)^2}{1-\frac{\ddot{w}}{W_c}}   \right) \\
        &= \frac{1}{W_c^2}\sum_{jc=1}^{Jc} \frac{\ddot{w}^2(\overline{T}_{jc}-\hat{\mu_{c}})^2}{(1-\frac{\ddot{w}}{W_c})} \\
\end{split}
\end{equation}

where $A_{jc} = (1-(\tilde{w}_{jc}/W_c))^{-1/2}$. We are assuming a CHE model is correct, so $\Phi_{jc}$ is the same for both CHE and CE. The weight matrices are different though. Also $var(\hat{\mu_c}) \approx \frac{1}{W_c}$

%Where For $\mathbf{e}_{jc} = \mathbf{T}_{jc}- \mathbf{X}_{jc}\hat{\mathbf{\beta}} = \mathbf{1}_{jc}\overline{T}_{jc} - \mathbf{1}_{jc}\mathbf{b}_{jc}\hat{\mathbf{\beta}}$ is the vector for residuals for study $jc$ with $k_{jc} \times 1$ dimensions. 

The $\mathbf{A}_{jc}$ matrix is an adjustment matrix for small samples \autocite{tipton2015b}. In my context it becomes:

\begin{equation}
    \begin{split}
        A_{jc} &= \mathbf{W}_{jc}^{-1/2} \left[\mathbf{W}_{jc}^{-1/2} \left( \mathbf{W}_{jc}^{-1} - \mathbf{X}_{jc}\mathbf{M}\mathbf{X}_{jc}'\right) \mathbf{W}_{jc}^{-1/2}\right]^{-1/2} \mathbf{W}_{jc}^{-1/2} \\
                &= \mathbf{W}_{jc}^{-1/2} \left[\mathbf{W}_{jc}^{-1/2} \left( \mathbf{W}_{jc}^{-1} - \mathbf{1}_{jc}\mathbf{b}_{jc}\frac{1}{W_c}\mathbf{b}_{jc}'\mathbf{1}_{jc}'\right) \mathbf{W}_{jc}^{-1/2}\right]^{-1/2} \mathbf{W}_{jc}^{-1/2} \\
                &= \mathbf{W}_{jc}^{-1/2} \left[\mathbf{W}_{jc}^{-1/2} \left( \mathbf{W}_{jc}^{-1} - \frac{1}{W_c}\mathbf{1}_{jc}\mathbf{1}_{jc}'\right) \mathbf{W}_{jc}^{-1/2}\right]^{-1/2} \mathbf{W}_{jc}^{-1/2} \\   
                &= \mathbf{W}_{jc}^{-1/2} \left[  \mathbf{W}_{jc}^{-1/2}\mathbf{W}_{jc}^{-1}\mathbf{W}_{jc}^{-1/2} - \frac{1}{W_c}\mathbf{W}_{jc}^{-1/2}\mathbf{1}_{jc}\mathbf{1}_{jc}' \mathbf{W}_{jc}^{-1/2}\right]^{-1/2} \mathbf{W}_{jc}^{-1/2} \\ 
                &= \mathbf{W}_{jc}^{-1/2} \left[  \mathbf{W}_{jc}^{-2} - \frac{1}{W_c}\left(\frac{\ddot{w}}{k_{jc}}\right)^{-1/2}\mathbf{1}_{jc}\mathbf{1}_{jc}' \left(\frac{\ddot{w}}{k_{jc}}\right)^{-1/2}\right]^{-1/2} \mathbf{W}_{jc}^{-1/2} \\ 
                &= \left[ \mathbf{W}_{jc}\mathbf{W}_{jc}^{-2}\mathbf{W}_{jc} - \frac{1}{W_c}\mathbf{W}_{jc}\left(\frac{\ddot{w}}{k_{jc}}\right)^{-1}\mathbf{1}_{jc}\mathbf{1}_{jc}'\mathbf{W}_{jc}\right]^{-1/2}  \\ 
                &= \left[ \mathbf{I}_{jc} - \frac{1}{W_c}\left(\frac{\ddot{w}}{k_{jc}}\right)\left(\frac{\ddot{w}}{k_{jc}}\right)^{-1}\mathbf{1}_{jc}\mathbf{1}_{jc}'\left(\frac{\ddot{w}}{k_{jc}}\right)\right]^{-1/2}  \\ 
                &= \left[ \mathbf{I}_{jc} - \frac{\ddot{w}}{k_{jc}W_c}\mathbf{1}_{jc}\mathbf{1}_{jc}'\right]^{-1/2}  \\ 
    \end{split}
    \nonumber
\end{equation}
